{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T17:51:58.043824Z",
     "start_time": "2020-11-09T17:51:57.896492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov 10 01:51:57 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.100      Driver Version: 440.100      CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:0A:00.0  On |                  N/A |\r\n",
      "|  0%   53C    P2   178W / 300W |  10921MiB / 11016MiB |     75%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:0B:00.0 Off |                  N/A |\r\n",
      "|  0%   52C    P2   162W / 260W |   9807MiB / 11019MiB |     85%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      1141      G   /usr/lib/xorg/Xorg                            18MiB |\r\n",
      "|    0      1403      G   /usr/bin/gnome-shell                          56MiB |\r\n",
      "|    0      2036      G   /usr/lib/xorg/Xorg                            92MiB |\r\n",
      "|    0      2165      G   /usr/bin/gnome-shell                          79MiB |\r\n",
      "|    0      8803      C   python                                      9841MiB |\r\n",
      "|    0     13638      C   ...p307-2-4/anaconda3/envs/tu36/bin/python   819MiB |\r\n",
      "|    1      8803      C   python                                      9795MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### original datamgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T17:52:00.250581Z",
     "start_time": "2020-11-09T17:51:58.045661Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deep307-2-4/anaconda3/envs/tu36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/deep307-2-4/anaconda3/envs/tu36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/deep307-2-4/anaconda3/envs/tu36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/deep307-2-4/anaconda3/envs/tu36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/deep307-2-4/anaconda3/envs/tu36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/deep307-2-4/anaconda3/envs/tu36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from data.datamgr import SetDataManager, DataManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T17:52:00.258812Z",
     "start_time": "2020-11-09T17:52:00.251705Z"
    }
   },
   "outputs": [],
   "source": [
    "base_file = 'filelists/omniglot/base.json'\n",
    "image_size = 28\n",
    "n_query = 15\n",
    "few_shot_params = dict(n_way = 3, n_support = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T17:52:00.486767Z",
     "start_time": "2020-11-09T17:52:00.259830Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deep307-2-4/anaconda3/envs/tu36/lib/python3.6/site-packages/torchvision/transforms/transforms.py:211: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n"
     ]
    }
   ],
   "source": [
    "base_datamgr = SetDataManager(image_size, n_query = n_query,  **few_shot_params)\n",
    "base_loader = base_datamgr.get_data_loader( base_file , aug = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T17:52:00.493704Z",
     "start_time": "2020-11-09T17:52:00.488167Z"
    }
   },
   "outputs": [],
   "source": [
    "read_data = False\n",
    "if read_data:\n",
    "    first_data = base_loader.dataset[0]\n",
    "    print('first_data[0].type():', first_data[0].type())\n",
    "    print('first_data[1].type():', first_data[1].type())\n",
    "    for i, (x,_ ) in enumerate(base_loader):\n",
    "        print(x.shape)\n",
    "        print(_.shape)\n",
    "        print(x.type())\n",
    "        print(_.type())\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### customized datamgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T17:52:00.501419Z",
     "start_time": "2020-11-09T17:52:00.494650Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.18.4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# import torch\n",
    "# import torchvision.transforms as transforms\n",
    "# from data.dataset import EpisodicBatchSampler\n",
    "from data.datamgr import VirtualSetDataManager, load_npz_dataset\n",
    "# from data.dataset import VirtualSetDataset\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T17:52:00.505825Z",
     "start_time": "2020-11-09T17:52:00.502427Z"
    }
   },
   "outputs": [],
   "source": [
    "n_dims = 100\n",
    "n_all_classes = 600 # base max 400 / source_val 100 / source_novel 100\n",
    "n_samples_per_class = 40 # i think 40 is enough\n",
    "n_classes = {\n",
    "    'base':400, 'val':100, 'novel':100, \n",
    "    'base25cl':25, 'base50cl':50, 'base100cl':100, 'base200cl':200,}\n",
    "distrib_center = np.zeros(n_dims)\n",
    "distrib_std = 20 * np.ones(n_dims)\n",
    "# base_distrib_radius = 1\n",
    "# base_x_std = 1\n",
    "cls_x_std = 4\n",
    "\n",
    "n_target_classes = 200\n",
    "n_val_classes = 100\n",
    "n_novel_classes = 100\n",
    "target_distrib_center = 1 * np.ones(n_dims)\n",
    "target_distrib_radius = 1\n",
    "target_x_std = 1\n",
    "target_cls_x_std = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T17:52:00.508574Z",
     "start_time": "2020-11-09T17:52:00.507157Z"
    }
   },
   "outputs": [],
   "source": [
    "# n_base_informative = 20 # first 20 features\n",
    "# n_target_informative = 50 # first 50 features\n",
    "# assert n_base_informative <= n_dims\n",
    "# assert n_target_informative <= n_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T17:52:00.526587Z",
     "start_time": "2020-11-09T17:52:00.509521Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "'''\n",
    "base dataset: \n",
    "    different n_classes\n",
    "    (different n_samples_per_class?)\n",
    "    \n",
    "target dataset:\n",
    "    different domain shift\n",
    "'''\n",
    "\n",
    "# def load_dataset(path):\n",
    "#     assert '.npz' in path, 'load path should be .npz file'\n",
    "#     data = np.load(path)\n",
    "#     return data['X'], data['y']\n",
    "\n",
    "class DatasetGenerator:\n",
    "    def __init__(self, n_dims, n_all_classes, n_classes, n_samples_per_class):#, datafolder='./'):\n",
    "        self.n_dims = n_dims\n",
    "        self.n_all_classes = n_all_classes\n",
    "        self.n_classes = n_classes # dictionary base50cl/base400cl/val/novel\n",
    "        self.n_samples_per_class = n_samples_per_class\n",
    "        self.n_samples = n_all_classes * n_samples_per_class\n",
    "#         self.datafolder = datafolder\n",
    "        assert n_all_classes == n_classes['base'] + n_classes['val'] + n_classes['novel']\n",
    "        \n",
    "    def gen_random_dataset(self, save_path=None):\n",
    "        n_samples = self.n_samples_per_class * self.n_all_classes\n",
    "        X_shape = (n_samples, self.n_dims)\n",
    "        X = np.random.random(X_shape)\n",
    "        y = np.repeat(np.arange(self.n_all_classes),self.n_samples_per_class,axis=0) # [0 0 1 1 2 2 ...]\n",
    "        if save_path is not None:\n",
    "            assert '.npz' in save_path, 'save path should be .npz file'\n",
    "            np.savez(save_path, X=X, y=y)#, X_mean=X.mean(axis=0), X_std=X.std(axis=0))\n",
    "        return X, y\n",
    "        \n",
    "    def gen_Gaussian_datasets(self, datafolder, distrib_center, distrib_std, cls_x_std, informative_interval):\n",
    "        ''' generate base100cl, base200cl, base400cl, val, novel datasets\n",
    "        '''\n",
    "        n_informative = informative_interval[1] - informative_interval[0] + 1\n",
    "        distrib_center_info_feat = distrib_center[informative_interval[0]:informative_interval[1]+1]\n",
    "        distrib_std_info_feat = distrib_std[informative_interval[0]:informative_interval[1]+1] # actually no need that complex currently\n",
    "        informative_x_centers = np.random.normal(\n",
    "            loc = distrib_center_info_feat, scale = distrib_std_info_feat, \n",
    "            size = (self.n_all_classes, n_informative)\n",
    "        ) # shape: (n_all_classes, n_informative)\n",
    "#         print(informative_x_centers.shape)\n",
    "        X_info = []\n",
    "        for cl in range(self.n_all_classes):\n",
    "            info_x_center = informative_x_centers[cl]\n",
    "            cl_X_info = np.random.normal(\n",
    "                loc = info_x_center, scale = cls_x_std, \n",
    "                size = (self.n_samples_per_class, n_informative)\n",
    "#                 size = (n_informative, self.n_samples_per_class) # this would get error @@\n",
    "            )\n",
    "            X_info.append(cl_X_info)\n",
    "        X_info = np.concatenate(X_info, axis=0)\n",
    "        X_noninfo_center = distrib_center[:-n_informative] # hack (actually should be dimensions except informative_interval)\n",
    "        X_noninfo_std = distrib_std[:-n_informative] # hack (actually should be dimensions except informative_interval)\n",
    "        X_noninfo = np.random.normal(\n",
    "            loc = X_noninfo_center, scale = X_noninfo_std, \n",
    "            size = (self.n_samples, self.n_dims-n_informative)\n",
    "        )\n",
    "        X1 = X_noninfo[:, :informative_interval[0]] # hack\n",
    "        X2 = X_noninfo[:, informative_interval[0]:] # hack\n",
    "        X_all = np.concatenate(\n",
    "            (X1, X_info, X2)\n",
    "            , axis=1)\n",
    "        y_all = np.repeat(np.arange(self.n_all_classes),self.n_samples_per_class,axis=0) # [0 0 1 1 2 2 ...]\n",
    "        test_dataset_ls = ['val', 'novel']\n",
    "        Xs = {}\n",
    "        ys = {}\n",
    "#         for split in test_dataset_ls:\n",
    "        for split in self.n_classes.keys():\n",
    "            dataset_n_classes = self.n_classes[split]\n",
    "            dataset_n_samples = dataset_n_classes * self.n_samples_per_class\n",
    "            if 'base' in split:\n",
    "                X = X_all[:dataset_n_samples]\n",
    "                y = y_all[:dataset_n_samples]\n",
    "            elif split == 'novel':\n",
    "                X = X_all[-dataset_n_samples:]\n",
    "                y = y_all[-dataset_n_samples:]\n",
    "            elif split == 'val':\n",
    "                novel_n_samples = self.n_classes['novel'] * self.n_samples_per_class\n",
    "                X = X_all[-novel_n_samples-dataset_n_samples:-novel_n_samples]\n",
    "                y = y_all[-novel_n_samples-dataset_n_samples:-novel_n_samples]\n",
    "            else:\n",
    "                raise ValueError('Unknown split: %s'%(split))\n",
    "\n",
    "            Xs[split] = X\n",
    "            ys[split] = y\n",
    "            filename = split + '.npz'\n",
    "            out_path = os.path.join(datafolder, filename)\n",
    "            print('Saving file: %s'%(out_path))\n",
    "            if not os.path.exists(datafolder):\n",
    "                print('Folder not exist: \"%s\"'%(datafolder))\n",
    "                print('Making directory...')\n",
    "                os.makedirs(datafolder)\n",
    "            np.savez(out_path, X=X, y=y)\n",
    "        \n",
    "        return Xs, ys\n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T17:52:00.530722Z",
     "start_time": "2020-11-09T17:52:00.528060Z"
    }
   },
   "outputs": [],
   "source": [
    "# filepath = 'filelists/virtual_20info/try_base200cl.npz'\n",
    "\n",
    "datafolder = './'\n",
    "dataset_generator = DatasetGenerator(\n",
    "    n_dims = n_dims, n_all_classes = n_all_classes, n_classes = n_classes, \n",
    "    n_samples_per_class = n_samples_per_class)#, datafolder = datafolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T17:52:00.534646Z",
     "start_time": "2020-11-09T17:52:00.531787Z"
    }
   },
   "outputs": [],
   "source": [
    "should_gen_npy = False\n",
    "if should_gen_npy:\n",
    "    filepath = '000.npz'\n",
    "    X, y = dataset_generator.gen_random_dataset(save_path=file_path)\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    X, y = load_npz_dataset(file_path)\n",
    "    print(X.shape)\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T17:52:01.207074Z",
     "start_time": "2020-11-09T17:52:00.535736Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datafolder: filelists/virtual_info0029/\n",
      "Saving file: filelists/virtual_info0029/base.npz\n",
      "Folder not exist: \"filelists/virtual_info0029/\"\n",
      "Making directory...\n",
      "Saving file: filelists/virtual_info0029/val.npz\n",
      "Saving file: filelists/virtual_info0029/novel.npz\n",
      "Saving file: filelists/virtual_info0029/base25cl.npz\n",
      "Saving file: filelists/virtual_info0029/base50cl.npz\n",
      "Saving file: filelists/virtual_info0029/base100cl.npz\n",
      "Saving file: filelists/virtual_info0029/base200cl.npz\n",
      "datafolder: filelists/virtual_info1039/\n",
      "Saving file: filelists/virtual_info1039/base.npz\n",
      "Folder not exist: \"filelists/virtual_info1039/\"\n",
      "Making directory...\n",
      "Saving file: filelists/virtual_info1039/val.npz\n",
      "Saving file: filelists/virtual_info1039/novel.npz\n",
      "Saving file: filelists/virtual_info1039/base25cl.npz\n",
      "Saving file: filelists/virtual_info1039/base50cl.npz\n",
      "Saving file: filelists/virtual_info1039/base100cl.npz\n",
      "Saving file: filelists/virtual_info1039/base200cl.npz\n",
      "datafolder: filelists/virtual_info2049/\n",
      "Saving file: filelists/virtual_info2049/base.npz\n",
      "Folder not exist: \"filelists/virtual_info2049/\"\n",
      "Making directory...\n",
      "Saving file: filelists/virtual_info2049/val.npz\n",
      "Saving file: filelists/virtual_info2049/novel.npz\n",
      "Saving file: filelists/virtual_info2049/base25cl.npz\n",
      "Saving file: filelists/virtual_info2049/base50cl.npz\n",
      "Saving file: filelists/virtual_info2049/base100cl.npz\n",
      "Saving file: filelists/virtual_info2049/base200cl.npz\n",
      "datafolder: filelists/virtual_info3059/\n",
      "Saving file: filelists/virtual_info3059/base.npz\n",
      "Folder not exist: \"filelists/virtual_info3059/\"\n",
      "Making directory...\n",
      "Saving file: filelists/virtual_info3059/val.npz\n",
      "Saving file: filelists/virtual_info3059/novel.npz\n",
      "Saving file: filelists/virtual_info3059/base25cl.npz\n",
      "Saving file: filelists/virtual_info3059/base50cl.npz\n",
      "Saving file: filelists/virtual_info3059/base100cl.npz\n",
      "Saving file: filelists/virtual_info3059/base200cl.npz\n"
     ]
    }
   ],
   "source": [
    "should_gen_Gaussian = True\n",
    "informative_intervals = [(0, 29), (10, 39), (20, 49), (30, 59)]\n",
    "# info_interval = (0, 29)\n",
    "for info_interval in informative_intervals:\n",
    "    info_int_s1 = str(info_interval[0]).zfill(2)\n",
    "    info_int_s2 = str(info_interval[1]).zfill(2)\n",
    "    datafolder = 'filelists/virtual_info%s%s/'%(info_int_s1, info_int_s2)\n",
    "    print('datafolder:', datafolder)\n",
    "    if should_gen_Gaussian:\n",
    "        dataset_generator.gen_Gaussian_datasets(\n",
    "            datafolder = datafolder, \n",
    "            distrib_center=distrib_center, distrib_std=distrib_std, \n",
    "            cls_x_std=cls_x_std, informative_interval=info_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T17:52:01.417929Z",
     "start_time": "2020-11-09T17:52:01.208196Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aaa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-972a1a11f199>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maaa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'aaa' is not defined"
     ]
    }
   ],
   "source": [
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T17:52:01.419921Z",
     "start_time": "2020-11-09T17:51:55.980Z"
    }
   },
   "outputs": [],
   "source": [
    "base_datamgr = VirtualSetDataManager(in_dim = n_dims, n_query = 15,  **few_shot_params)\n",
    "base_loader = base_datamgr.get_data_loader( filepath = filepath, aug = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T17:52:01.420316Z",
     "start_time": "2020-11-09T17:51:55.982Z"
    }
   },
   "outputs": [],
   "source": [
    "first_data = base_loader.dataset[0]\n",
    "print('first_data[0].type():', first_data[0].type())\n",
    "print('first_data[1].type():', first_data[1].type())\n",
    "\n",
    "for i, (x,y ) in enumerate(base_loader):\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    print(x.type())\n",
    "    print(y.type())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tu36]",
   "language": "python",
   "name": "conda-env-tu36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
